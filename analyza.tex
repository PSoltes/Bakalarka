\newpage
\chapter{Analıza}
\label{ch:Analıza}

Keïe cie¾om tejto práce je implementácia biologicky inšpirovaného algoritmu v jazyku R, tak je potrebné lepšie si ozrejmi a oboznámi sa s pojmami, ktoré súvisia s biologicky inšpirovanımi algoritmami. Je dôleité pochopi, èo je to optimalizácia a ako sa formálne zapisuje, pretoe hlavnım cie¾om biologicky inšpirovanıch algoritmov je h¾ada optimálne riešenia (zvyèajne maximalizaèného alebo minimalizaèného problému). Ïalej je dôleité pozna aké funkcie a vstupy riešia biologicky inšpirované algoritmy a ako sa delia. Pozna formálny zápis optimalizácie je dôleité aj z poh¾adu návrhu a implementácie algoritmu pre lepšiu parametrizáciu a zadanie problému nášmu algoritmu. V neposlednom rade je podstatné pochopi, aké biologicky inšpirované algoritmy u poznáme, èím sa líšia, a ako sa delia a ako ich najlepšie poui.
Cie¾om tejto kapitoly a jej sekcií je tieto pojmy ozrejmi a zasadi do kontextu návrhu a implementácie biologicky inšpirovaného algoritmu v jazyku R.

\section{Matematická optimalizácia}
\label{ch:Matematická optimalizácia}
Matematická optimalizácia je proces
\begin{my_itemize}
 \item formulácie a
 \item riešenia ohranièeného optimalizaèného problém vo všeobecnej matematickej forme
\end{my_itemize}

\begin{equation}  
    minimize_{w.r.t. x} f(x), x = [x_1, x_2, ... x_n]^T \in \mathbb{R}
\end{equation}

pre èo platia ohranièenia

\begin{equation}
g_j(x) ? 0, j= 1, 2, . . . , m
\end{equation}
\begin{equation}
h_j(x) = 0, j= 1, 2, . . . , r
\end{equation}

kde funkcie \(f(x)\), \(g_j(x)\) a \(h_j(x)\) sú skalárne funkcie
reálneho ståpcového vektora x. Funkcia \(f(x)\) sa nazıva cie¾ová funkcia, funkcie \(g_j(x)\) opisujú jednotlivé nerovnostné obmedzenia pre premenné vektora x a funkcie \(h_j(x)\) opisujú obmedzenia rovnosti pre premenné vektora x.

Optimálny vektor x, ktorı rieši optimalizaènı problém sa zvyèajne oznaèuje \(x^*\) a hodnota \(f(x^*)\) je optimálna tzn. väèšinou minimálna alebo maximálna, hodnota funkcie\cite{1}.

\subsection{Druhy optimalizaènıch problémov}

Optimalizaèné problémy sa delia pod¾a rôznych kritérií, najbenejšie sú:

\begin{my_itemize}
 \item obmedzenie
 \item poèet cie¾ov tzn. ko¾ko cie¾ovıch funkcií chceme minimalizova/maximalizova
 \item poèet uspokojivıch riešení
\end{my_itemize}

\subsubsection{Optimalizaèné problémy pod¾a obmedzenia}

Pod¾a obmedzení sa problémy delia na:

\begin{my_itemize}
 \item obmedzené tj. problémy, pre ktoré mnoina funkcií obmedzení \(g_j(x)\) a \(h_j(x)\) nie je prázdna
 \item neobmedzené tj. problémy, pre ktoré neexistujú obmedzenia \(g_j(x)\) a \(h_j(x)\)
\end{my_itemize}

\subsubsection{Optimalizaèné problémy pod¾a poètu cie¾ov}

Pod¾a poètu cie¾ov sa problémy delia:
\begin{my_itemize}
 \item jednokriteriálne
 \item multikriteriálne
\end{my_itemize}

Pri problémoch s viacerımi cie¾mi má kadı cie¾ svoju vlastnú minimálnu hodnotu, avšak pri riešení takıchto úloh treba do úvahy bra rozumnı kompromis medzi minimami jednotlivıch cie¾ov. Prípustná miera kompromisu medzi hodnotami cie¾ovıch funkcií je èasto daná obmedzeniami. 

\subsubsection{Optimalizaèné problémy pod¾a poètu uspokojivıch riešení}

Pod¾a poètu uspokojivıch riešení sa problémy delia:

\begin{my_itemize}
 \item unimodálne
 \item multimodálne
\end{my_itemize}

Niektoré optimalizaèné problémy majú viacero uspokojivıch riešení. Problémy, pri ktorıch chceme nájs všetky takéto riešenia sa nazıvajú multimodálne. Tieto riešenia môu by všetky rovnako dobré, alebo niektoré riešenia môu by dobré len pre špecifickıch podmienkach.
%\bigskip
%V tejto práci sa budeme navrhova a implementova algoritmus, ktorı rieši aj obmedzené, aj neobmedzené, unimodálne problémy s jednım cie¾om.

\subsection{Preh¾ad spôsobov riešenia optimalizaènıch problémov}

Na riešenie optimalizaènıch problémov existuje mnostvo spôsobov a venuje sa mu mnostvo odborov. Táto práce je hlavne orientovaná na metaheuristky \ref{Metaheuristiky a heuristiky} inšpirované prírodou, ktorım sa budem venova v ïalších èastiach. Ïalšími odbormi, ktoré sa venujú optimalizaènım problému sú napríklad dynamické alebo lineárne programovanie.\cite{MetahYang} V tejto èasti však ponúknem len zopár príkladov z mnostva algoritmov a spôsobov riešenia optimalizaènıch problémov.

\subsubsection{Dynamické a lineárne programovanie}

Dynamické programovanie je spôsob vytvárania riešení algoritmov, ktorı je zaloenı na princípe rekurencie v urèitıch optimalizaènıch problémoch. Pri pouití dynamického programovania sa dá predpoklada, e je moné vyráta hodnotu cie¾ovej funkcie \(f_k(x)\) z hodnoty cie¾ovej funkcie \(f_{k-1}(x)\) na základe rekurentného vzahu. Následne sa vytvorí tabu¾ka, v ktorej budú všetky moné monosti a z nich sa vyberie tá najlepšia. Z charakteristiky dynamického programovanie je však vidno, e dynamické programovanie je vhodnejšie pre h¾adanie optima z danıch diskrétnych hodnôt vektora x.\cite{4}

Problémy lineárneho programovania sú optimalizaèné problémy, ktoré spåòajú vlastnosti proporcionality tzn. ak chceme dvojnásobne zvıši vısledok, dvojnásobne zvıšime vstup do problému, nezápornosti tzn. nie je moné poui záporné vstupy a všeobecne sú charakterizované lineárnymi závislosami a podmienkami, napr.

\begin{equation}
    \begin{split}
    x_1 ... + a_{1,m+1}x_{m+1} ... a_{1,n}x_{n} = b_1\\
    .               .                   .           .\\
    .               .                   .           .\\
    .               .                   .           .\\
    x_n ... + a_{n,m+1}x_{m+1} ... a_{n,n}x_{n} = b_n\\
    (-z) ... + c_{m+1}x_{m+1} ...  c_{n}x_{n} = (-z_0)\\
    \end{split}
\end{equation}

Prvım a najjednoduchším algoritmom na optimalizáciu problémov lineárneho programovania bol algoritmus simplex.\newline
Algoritmus simplex je charakterizovanı vytvorením jedného náhodného riešenia na konvexnom geometrickom útvare, ktorého vrcholy sú riešenia lineárneho problému. Algoritmus sa tak pohybuje po hranách ku lepším riešeniam.
\cite{5}

\subsubsection{Iteratívne metódy}

V dnešnej dobe za pomoci modernıch poèítaèov je jednoduchšie h¾ada optimálne riešenie po krokoch, v ktorıch sa postupne riešenie zlepšuje, ako h¾ada celé riešenie naraz. Takıto postup je charakterizovanı rovnicou

\begin{equation}\label{iteratívnı vzorec}
    x^{t+1} = x^t + \alpha^td^t
\end{equation}

, kde \(\alpha^t\) je skalár definujúci dåku kroku a \(d^t\) je smer h¾adania zostupu resp. vıstupu. Spôsob h¾adanie \(d^t\) je rôzny pre rôzne optimalizaèné algoritmy.\cite{3} Najjednoduchšími algoritmami sledujúcimi tento vzorec sú Metóda najstrmšieho vıstupu (Steepest descent/ascent method) a Koordinátová metóda najstrmšieho vıstupu resp. zostupu (Coordinate steepest descent/ascent method).

Metóda najstrmšieho vıstupu resp. zostupu sa dá poui ak vieme vyráta parciálne derivácie optimalizaènej funkcie, èo znamená, e vieme urèi gradient \(\nabla f(x) \), èo je vlastne smer vıstupu v danom bode funkcie. Potom ak dosadíme do rovnice \ref{iteratívnı vzorec} \(d^t = -\nabla f(x)\), vieme s dostatoène malım krokom iterácie \(\alpha^t\) dosiahnu optimálne riešenie. Dåka kroku sa môe ráta pomocou Armijovho pravidla\cite{2}.

\begin{equation}
 f(x^t - \alpha \nabla f(x^t)) - f(x^t) ? ?\sigma \alpha ||\nabla f(x^t)||^2
\end{equation}

Koordinátová metóda najstrmšieho vıstupu je odvodená od metódy najstrmšieho vıstupu avšak pri kadom kroku zlepšujeme vısledok len v oh¾ade na jedno \(x_i\) z optimalizaènej funkcie \(f(x_1, x_2, ... x_i, ... x_n)\). Tieto èasti vektora môeme optimalizova v smere z¾ava doprava, tam a naspä alebo optimalizujeme komponent s najväèšou absolútnou hodnotou
\cite{3}.

\section{Metaheuristiky a heuristiky}\label{Metaheuristiky a heuristiky}
Heuristky sú spôsoby optimalizácie, ktoré negarantujú nájdenie optimálneho riešenia. Tieto spôsoby riešenia optimalizaènıch problémov fungujú na princípe náhodného h¾adania a vyuívania doteraz nájdenıch najlepších vısledkov. Metaheuristiky sú heuristiky, ktoré sú nezávislé od jedného problému a je ich moné poui na ve¾ké mnostvo rozliènıch problémov. Metaheuristiky sú v dnešnej dobe ve¾mi populárne, pretoe ponúkajú rozumnı kompromis medzi nájdením nie úplne optimálneho riešenia a nájdením riešenia v rozumnom èase. Najväèším problémom metaheuristík je ako robi kompromis medzi vyuívaním najlepšieho nájdeného riešenia a riešení blízko neho (zosilnenie) a preh¾adávaním priestoru riešení (diverzifikácia). Obe tieto èinnosti sú dôleité, lebo priestor okolo zatia¾ najlepšieho riešenia pravdepodobne ponúka aj ïalšie rovnako dobré alebo lepšie riešenia, avšak tento priestor môe by priestor lokálneho optima, preto je dôleité ïalej preh¾adáva priestor riešení. Ïalšími dôleitımi rozhodnutiami pri návrhu a implementácií heuristík a metaheuristík je rozhodnutie ako reprezentova optimalizaènı problém a ako urèova úspešnos riešenia pomocou cie¾ovej funkcie.

Efektívna reprezentácia optimalizaèného problému je dôleitou èasou navrhovania heuristiky. Efektivita reprezentácie problému je silno ovplyvnená spôsobom vıpoètu cie¾ovej funkcie a spôsobom h¾adania v priestore riešení. Reprezentácia musí ma tieto vlastnosti:

\begin{my_itemize}
 \item \textbf{Úplnos} - musíme vedie reprezentova kadé riešenie v priestore riešení. 
 \item \textbf{Spojitos} - kadé riešenie musí by nejakım spôsobom dosiahnute¾né
 \item \textbf{Efektívnos} - h¾adanie novıch riešení v priestore riešení musí by efektívne
\end{my_itemize}

Reprezentácie riešení môu by:

\begin{my_itemize}
 \item \textbf{Lineárne} - takéto reprezentácie si môeme predstavi ako vektor, napr. vektor hodnôt x funkcie, vektor jednotiek a núl, ktoré oznaèujú, èi i-ty prvok vektora je pouitı.
 \item \textbf{Nelineárne} - zvyèajne reprezentované grafovou štruktúrou, reprezentujú sa tam stavy jedno k jednej, jedno ku viacerım, viaceré ku jednej, medzi riešeniami a reprezentáciami riešení
\end{my_itemize}

Vo ve¾kom mnostve problémov môe by funkcia zadaného optimalizaèného problému aj jeho cie¾ovou funkciou. Typickım príkladom je optimalizácia spojitıch viac rozmernıch funkcií, kde sa optimum funkcie dá ¾ahko porovna ako èíslo. Avšak napríklad pri funkciách, ktorıch vısledkom je len pravdivostná hodnota, je aké odlíši lepšie a horšie riešenie. Pri takıchto prípadoch je moné napríklad hodnoti riešenie pod¾a toho ko¾ko èastí je nesprávnych etc.. Ïalším prípadom cie¾ovej funkcie, ktorú je potrebné upravova sú funkcie, ktoré je príliš nákladné poèíta. Takéto funkcie môu by nahradené funkciou, ktorá ráta odhad tejto funkcie a tak urıchli beh metaheuristiky\cite{MetaMainBook}.

Metaheuristiky a heuristiky môeme deli\cite{ReviewNatureInspired} pod¾a rôznych kritérií:
\begin{my_itemize}
 \item
 {
    \textbf{Prírodou inšpirované vs. Ostatné} - Prírodou inšpirované algoritmy môeme deli na
    \begin{my_itemize}
     \item Biologicky inšpirované \ref{fyz_chem_algo}
     \item Fyzikou a chémiou inšpirované \ref{bio_algo}
     \item Ostatné
    \end{my_itemize} 
 }
 \item \textbf{S pouitím pamäte vs. Bez pouitia pamäte} - heuristiky bez pouitia pamäte sú napríklad tie, ktoré pouívajú princíp Markovovej reaze, tzn. e si nepamätajú navštívené stavy
 \item \textbf{Zaloené na populácií vs. Zaloené na jednom riešení} - heuristiky zaloené na jednom riešení pouívajú len jedno zvyèajne najlepšie riešení a na základe neho ho vylepšujú.
 
 \item \textbf{Deterministické vs. Stochastické}
\end{my_itemize}
\cite{MetahYang,MetaMainBook,MetahA}

\subsection{Prírodou inšpirované algoritmy}
\subsubsection{Fyzikou a chémiou inšpirované algoritmy}\label{fyz_chem_algo}
Fyzikou inšpirované algoritmy sú, ako je zrejmé z názvu, optimalizaèné algoritmy inšpirované fyzikálnymi procesmi a zákonmi vo vesmíre. Zaèiatok takıchto algoritmov mono h¾ada po publikovaní práce o kvantovo-inšpirovanıch poèítaèoch v roku 1982\cite{QMechComp}. Táto práca otvorila cestu prvému fyzikálne zaloenému algoritmu v roku 1995 nazvanému Kvantovo-inšpirovanı genetickı algoritmus\cite{QIGA}. Hlavnı "boom" takıchto algoritmov sa zaèal po roku 2000, keï sa zaèali vznika fyzikálne algoritmy inšpirované rôznymi oblasami fyzika ako je Newtonov gravitaènı zákon (Algoritmus gravitaènım h¾adaním - GSA, Optimalizácia centrálnou silou - CFO,...), teóriou vesmíru (Big Bang Big Crunch), elektromagnetizmom  alebo kvantovou mechanikou (Kvantovo inšpirovanı roj èastíc - QIPS).\cite{PhysicsSurvey}
\subsubsection*{Kvantovo-inšpirovanı genetickı algoritmus}
Tento fyzikálne inšpirovanı algoritmus je prvı z fyzkálne inšpirovanıch algoritmov a vznikol v roku 1995. Tento algoritmus je zaloenı  na benom genetickom algoritme, kde populácia chromozómov riešení mutuje, kríi sa a na základe následne vypoèítanej fitnes funkcie novo vzniknutıch jedincov sa vyberie n jedincov do ïalšej generácie. V tomto algoritme sa však pri vıpoète neberie do úvahy len "dobros" riešenia, ale aj to ako ve¾mi sa líšia riešenia od najlepšieho riešenia (èím viac, tım lepšie). Takımto spôsobom sa udriavame lokálne optimá, ktoré potom pomáhajú pri h¾adaní globálnych optím.
Odlišnosou tohoto algoritmu od beného genetického algoritmu je pouitie princípu superpozície elektrónov. Superpozícia elektrónov znamená, e pod¾a toho akú energiu má elektrón, tak sa môe s nejakou pravdepodobnos nachádza na viacerıch vrstvách okolo jadra atómu. Toto je vyuité aj v tomto algoritme v zmysle, e existuje viacero vesmírov, kde sa rieši benı genetickı algoritmus a tieto sa môu navzájom kríi a mutova. Toto však môe nasta len medzi génmi v chromozóme na rovnakej pozícií i. Tımto sa simuluje preskakovanie elektrónu z vrstvy na vrstvu\cite{QIGA}.
\subsubsection*{Big Bang Big Crunch}
Big Bang Big Crunch je ïalším fyzikou inšpirovanım algoritmom. Hlavnım princípom, ktorım sa tento algoritmus inšpiruje je rozptılenie hmoty a energie vo vesmíre (Big bang) a následné zhlukovanie tejto hmoty vo vhodnıch pozíciách ako sa energia vesmíru zniuje (Big crunch). Tento algoritmus je zaloenı na populácií agentov, take sa dá klasifikova ako rojovı.
Algoritmus funguje tak, e najprv sa vytvorí poèiatoèná náhodná populácia v n-rozmernom priestore (Big bang). Potom sa pomocou rovnice \ref{BigCrunchEq} vypoèíta "stred hmoty", èie stred z vygenerovanıch bodov (Big crunch). 
\begin{equation}\label{BigCrunchEq}
   x^{\xrightarrow{}c} = \frac{\sum_{i=1}^{N}\frac{1}{f^i}x^{-i}}{\sum_{i=1}^{N}\frac{1}{f^i}}
\end{equation}
,  \(x^{i}\) je i-ty vygenerovanı bod a \(f^i\) je fitnes funkcia bodu \(x^i\).\newline
Následne zasa nasleduje fáza "Big bang", ktorá u ale negeneruje body náhodne, ale sú tieto body vygenerované rovnicou \ref{BigBangEq}, ktorá prièíta alebo odèíta èíslo na základe normálneho rozdelenia, ktorého variancia sa s pribúdajúcimi iteráciami zniuje.
\begin{equation}\label{BigBangEq}
x^{new} = x^{c} + lr/k
\end{equation}
,kde \(x^c\) je stred hmoty, l je hornı limit parametra, r je náhodné èíslo z normálneho rozdelenia a k je poèet iterácií.
Big crunch v tomto algoritme reprezentuje proces exploitácie a Big bang reprezentuje proces explorácie, ktorá sa ale s iteráciami zniuje, kvôli zniovaniu variancie a tım pádom nišej pravdepodobnosti vysokıch èísel. 
\subsubsection{Biologicky inšpirované algoritmy}\label{bio_algo}
 Biologicky inšpirované algoritmy sú druhom prírodou inšpirovanıch algoritmov, ktoré vznikli na základe pozorovania správania ivoèíchov alebo procesov ktorımi na nich vplıvala príroda. Takıto proces je napríklad evolúcia alebo symbióza. Algoritmy sa inšpirovali rôznymi druhmi zvierat, èi u malımi ako baktérie a salpy, alebo ve¾kımi ako veleryby alebo slony. Zvyèajne sa tieto algoritmy inšpirujú spôsobom h¾adania potravy alebo lovu tıchto zvierat. Príroda je dobrım zdrojom inšpirácie optimalizaènıch algoritmov, pretoe príroda mala milióny rokov na optimalizáciu správania zvierat a ivoèíchov. 
%\subsubsection*{Návrhové vzory pouité pri tvorbe biologicky inšpirovanıch algoritmov}
\subsubsection*{Evoluèné a genetické algoritmy}
Evoluèné a genetické algoritmy sú algoritmy zaloené na princípe evolúcie v prírode. Vo všeobecnosti sú to stochastické algoritmy zaloené na populácií, kde preíva nejsilnejší jedinec, tzn. jedinec s najlepšou hodnotou cie¾ovej funkcie. Vlastnos evolúcie je v tom, e populácie v ïalších iteráciách sú vytvorené z predchádzajúcich populácií mutaènımi a rozmnoovacími sa operátormi. Základy genetickıch algoritmov poloil John Holland v roku 1975\cite{JHollandGen}. Príkladom novšieho genetického algoritmu je Optimalizácia pomocou ryového po¾a\cite{PaddyField}. Genetické a evoluèné algoritmy rıchlo strácajú efektivitu pri multimodálnych a vysoko rozmernıch problémoch, kde je vysoká pravdepodobnos uviaznutia v lokálnom optime alebo potrebnı vysokı poèet iterácií.\cite{BioInspiredOverview}
\paragraph{Genetické simulované íhanie}
Genetické simulované íhanie je algoritmus, ktorı spája vlastnosti simulovaného íhania a genetického algoritmu. Algoritmus prebehne rovnako ako benı genetickı algoritmus, avšak na konci sa okrem najlepších, optimálnych riešení sa do populácie pridajú aj zlé riešenia na základe pravdepodobnosti p, ktorá sa s pribúdajúcimi iteráciami zmenšuje.\cite{needed}
\subsubsection*{Rojovo inšpirované algoritmy}
\subsubsection*{Ekológiou inšpirované algoritmy}
\subsubsection*{Ostatné (?)}
Medzi ostatné algoritmy patria všetky, ktoré sme dosia¾ nezaradili, take napríklad bio-inšpirované algoritmy, ktoré ale niesú rojovo inšpirované.
\paragraph{Optimalizácia ope¾ovaním kvetov}
\subsection{Ostatné (?)}
\subsubsection{Uèenie zaloené na opozící (Opposition based learning)}

\subsection{Biologicky inšpirované algoritmy v CRAN-e}
