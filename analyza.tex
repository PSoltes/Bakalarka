\newpage
\chapter{Analıza}
\label{ch:Analıza}

Keïe cie¾om tejto práce je implementácia biologicky inšpirovaného algoritmu v jazyku R, tak je potrebné lepšie si ozrejmi a oboznámi sa s pojmami, ktoré súvisia s biologicky inšpirovanımi algoritmami. Je dôleité pochopi, èo je to optimalizácia a ako sa formálne zapisuje, pretoe hlavnım cie¾om biologicky inšpirovanıch algoritmov je h¾ada optimálne riešenia (zvyèajne maximalizaèného alebo minimalizaèného problému). Ïalej je dôleité pozna aké funkcie a vstupy riešia biologicky inšpirované algoritmy a ako sa delia. Pozna formálny zápis optimalizácie je dôleité aj z poh¾adu návrhu a implementácie algoritmu pre lepšiu parametrizáciu a zadanie problému nášmu algoritmu. V neposlednom rade je podstatné pochopi, aké biologicky inšpirované algoritmy u poznáme, èím sa líšia, a ako sa delia a ako ich najlepšie poui.
Cie¾om tejto kapitoly a jej sekcií je tieto pojmy ozrejmi a zasadi do kontextu návrhu a implementácie biologicky inšpirovaného algoritmu v jazyku R.

\section{Matematická optimalizácia}
\label{ch:Matematická optimalizácia}
Matematická optimalizácia je proces
\begin{my_itemize}
 \item formulácie a
 \item riešenia ohranièeného optimalizaèného problém vo všeobecnej matematickej forme
\end{my_itemize}

\begin{equation}  
    minimize_{w.r.t. x} f(x), x = [x_1, x_2, ... x_n]^T \in \mathbb{R}
\end{equation}

pre èo platia ohranièenia

\begin{equation}
g_j(x) ? 0, j= 1, 2, . . . , m
\end{equation}
\begin{equation}
h_j(x) = 0, j= 1, 2, . . . , r
\end{equation}

kde funkcie \(f(x)\), \(g_j(x)\) a \(h_j(x)\) sú skalárne funkcie
reálneho ståpcového vektora x. Funkcia \(f(x)\) sa nazıva cie¾ová funkcia, funkcie \(g_j(x)\) opisujú jednotlivé nerovnostné obmedzenia pre premenné vektora x a funkcie \(h_j(x)\) opisujú obmedzenia rovnosti pre premenné vektora x.

Optimálny vektor x, ktorı rieši optimalizaènı problém sa zvyèajne oznaèuje \(x^*\) a hodnota \(f(x^*)\) je optimálna tzn. väèšinou minimálna alebo maximálna, hodnota funkcie\cite{1}.

\subsection{Druhy optimalizaènıch problémov}

Optimalizaèné problémy sa delia pod¾a rôznych kritérií, najbenejšie sú:

\begin{my_itemize}
 \item obmedzenie
 \item poèet cie¾ov tzn. ko¾ko cie¾ovıch funkcií chceme minimalizova/maximalizova
 \item poèet uspokojivıch riešení
\end{my_itemize}

\subsubsection{Optimalizaèné problémy pod¾a obmedzenia}

Pod¾a obmedzení sa problémy delia na:

\begin{my_itemize}
 \item obmedzené tj. problémy, pre ktoré mnoina funkcií obmedzení \(g_j(x)\) a \(h_j(x)\) nie je prázdna
 \item neobmedzené tj. problémy, pre ktoré neexistujú obmedzenia \(g_j(x)\) a \(h_j(x)\)
\end{my_itemize}

\subsubsection{Optimalizaèné problémy pod¾a poètu cie¾ov}

Pod¾a poètu cie¾ov sa problémy delia:
\begin{my_itemize}
 \item jednokriteriálne
 \item multikriteriálne
\end{my_itemize}

Pri problémoch s viacerımi cie¾mi má kadı cie¾ svoju vlastnú minimálnu hodnotu, avšak pri riešení takıchto úloh treba do úvahy bra rozumnı kompromis medzi minimami jednotlivıch cie¾ov. Prípustná miera kompromisu medzi hodnotami cie¾ovıch funkcií je èasto daná obmedzeniami. 

\subsubsection{Optimalizaèné problémy pod¾a poètu uspokojivıch riešení}

Pod¾a poètu uspokojivıch riešení sa problémy delia:

\begin{my_itemize}
 \item unimodálne
 \item multimodálne
\end{my_itemize}

Niektoré optimalizaèné problémy majú viacero uspokojivıch riešení. Problémy, pri ktorıch chceme nájs všetky takéto riešenia sa nazıvajú multimodálne. Tieto riešenia môu by všetky rovnako dobré, alebo niektoré riešenia môu by dobré len pre špecifickıch podmienkach.
%\bigskip
%V tejto práci sa budeme navrhova a implementova algoritmus, ktorı rieši aj obmedzené, aj neobmedzené, unimodálne problémy s jednım cie¾om.

\subsection{Preh¾ad spôsobov riešenia optimalizaènıch problémov}

Na riešenie optimalizaènıch problémov existuje mnostvo spôsobov a venuje sa mu mnostvo odborov. Táto práce je hlavne orientovaná na metaheuristky \ref{Metaheuristiky a heuristiky} inšpirované prírodou, ktorım sa budem venova v ïalších èastiach. Ïalšími odbormi, ktoré sa venujú optimalizaènım problému sú napríklad dynamické alebo lineárne programovanie.\cite{MetahYang} V tejto èasti však ponúknem len zopár príkladov z mnostva algoritmov a spôsobov riešenia optimalizaènıch problémov.

\subsubsection{Dynamické a lineárne programovanie}

Dynamické programovanie je spôsob vytvárania riešení algoritmov, ktorı je zaloenı na princípe rekurencie v urèitıch optimalizaènıch problémoch. Pri pouití dynamického programovania sa dá predpoklada, e je moné vyráta hodnotu cie¾ovej funkcie \(f_k(x)\) z hodnoty cie¾ovej funkcie \(f_{k-1}(x)\) na základe rekurentného vzahu. Následne sa vytvorí tabu¾ka, v ktorej budú všetky moné monosti a z nich sa vyberie tá najlepšia. Z charakteristiky dynamického programovanie je však vidno, e dynamické programovanie je vhodnejšie pre h¾adanie optima z danıch diskrétnych hodnôt vektora x.\cite{4}

Problémy lineárneho programovania sú optimalizaèné problémy, ktoré spåòajú vlastnosti proporcionality tzn. ak chceme dvojnásobne zvıši vısledok, dvojnásobne zvıšime vstup do problému, nezápornosti tzn. nie je moné poui záporné vstupy a všeobecne sú charakterizované lineárnymi závislosami a podmienkami, napr.

\begin{equation}
    \begin{split}
    x_1 ... + a_{1,m+1}x_{m+1} ... a_{1,n}x_{n} = b_1\\
    .               .                   .           .\\
    .               .                   .           .\\
    .               .                   .           .\\
    x_n ... + a_{n,m+1}x_{m+1} ... a_{n,n}x_{n} = b_n\\
    (-z) ... + c_{m+1}x_{m+1} ...  c_{n}x_{n} = (-z_0)\\
    \end{split}
\end{equation}

Prvım a najjednoduchším algoritmom na optimalizáciu problémov lineárneho programovania bol algoritmus simplex.\newline
Algoritmus simplex je charakterizovanı vytvorením jedného náhodného riešenia na konvexnom geometrickom útvare, ktorého vrcholy sú riešenia lineárneho problému. Algoritmus sa tak pohybuje po hranách ku lepším riešeniam.
\cite{5}

\subsubsection{Iteratívne metódy}

V dnešnej dobe za pomoci modernıch poèítaèov je jednoduchšie h¾ada optimálne riešenie po krokoch, v ktorıch sa postupne riešenie zlepšuje, ako h¾ada celé riešenie naraz. Takıto postup je charakterizovanı rovnicou

\begin{equation}\label{iteratívnı vzorec}
    x^{t+1} = x^t + \alpha^td^t
\end{equation}

, kde \(\alpha^t\) je skalár definujúci dåku kroku a \(d^t\) je smer h¾adania zostupu resp. vıstupu. Spôsob h¾adanie \(d^t\) je rôzny pre rôzne optimalizaèné algoritmy.\cite{3} Najjednoduchšími algoritmami sledujúcimi tento vzorec sú Metóda najstrmšieho vıstupu (Steepest descent/ascent method) a Koordinátová metóda najstrmšieho vıstupu resp. zostupu (Coordinate steepest descent/ascent method).

Metóda najstrmšieho vıstupu resp. zostupu sa dá poui ak vieme vyráta parciálne derivácie optimalizaènej funkcie, èo znamená, e vieme urèi gradient \(\nabla f(x) \), èo je vlastne smer vıstupu v danom bode funkcie. Potom ak dosadíme do rovnice \ref{iteratívnı vzorec} \(d^t = -\nabla f(x)\), vieme s dostatoène malım krokom iterácie \(\alpha^t\) dosiahnu optimálne riešenie. Dåka kroku sa môe ráta pomocou Armijovho pravidla\cite{2}.

\begin{equation}
 f(x^t - \alpha \nabla f(x^t)) - f(x^t) ? ?\sigma \alpha ||\nabla f(x^t)||^2
\end{equation}

Koordinátová metóda najstrmšieho vıstupu je odvodená od metódy najstrmšieho vıstupu avšak pri kadom kroku zlepšujeme vısledok len v oh¾ade na jedno \(x_i\) z optimalizaènej funkcie \(f(x_1, x_2, ... x_i, ... x_n)\).
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/hillClimbing.png}
    \caption{Postup optimalizácie metódou najstrmšieho vıstupu v jednom smere \cite{yuret1994genetic}}
    \label{fig:HillClimbing}
\end{figure}Tieto èasti vektora môeme optimalizova v smere z¾ava doprava, tam a naspä alebo optimalizujeme komponent s najväèšou absolútnou hodnotou
\cite{3}.

\section{Metaheuristiky a heuristiky}\label{Metaheuristiky a heuristiky}
Heuristky sú spôsoby optimalizácie, ktoré negarantujú nájdenie optimálneho riešenia. Tieto spôsoby riešenia optimalizaènıch problémov fungujú na princípe náhodného h¾adania a vyuívania doteraz nájdenıch najlepších vısledkov. Metaheuristiky sú heuristiky, ktoré sú nezávislé od jedného problému a je ich moné poui na ve¾ké mnostvo rozliènıch problémov. Metaheuristiky sú v dnešnej dobe ve¾mi populárne, pretoe ponúkajú rozumnı kompromis medzi nájdením nie úplne optimálneho riešenia a nájdením riešenia v rozumnom èase. Najväèším problémom metaheuristík je ako robi kompromis medzi vyuívaním najlepšieho nájdeného riešenia a riešení blízko neho (zosilnenie) a preh¾adávaním priestoru riešení (diverzifikácia). Obe tieto èinnosti sú dôleité, lebo priestor okolo zatia¾ najlepšieho riešenia pravdepodobne ponúka aj ïalšie rovnako dobré alebo lepšie riešenia, avšak tento priestor môe by priestor lokálneho optima, preto je dôleité ïalej preh¾adáva priestor riešení. Ïalšími dôleitımi rozhodnutiami pri návrhu a implementácií heuristík a metaheuristík je rozhodnutie ako reprezentova optimalizaènı problém a ako urèova úspešnos riešenia pomocou cie¾ovej funkcie.

Efektívna reprezentácia optimalizaèného problému je dôleitou èasou navrhovania heuristiky. Efektivita reprezentácie problému je silno ovplyvnená spôsobom vıpoètu cie¾ovej funkcie a spôsobom h¾adania v priestore riešení. Reprezentácia musí ma tieto vlastnosti:

\begin{my_itemize}
 \item \textbf{Úplnos} - musíme vedie reprezentova kadé riešenie v priestore riešení. 
 \item \textbf{Spojitos} - kadé riešenie musí by nejakım spôsobom dosiahnute¾né
 \item \textbf{Efektívnos} - h¾adanie novıch riešení v priestore riešení musí by efektívne
\end{my_itemize}

Reprezentácie riešení môu by:

\begin{my_itemize}
 \item \textbf{Lineárne} - takéto reprezentácie si môeme predstavi ako vektor, napr. vektor hodnôt x funkcie, vektor jednotiek a núl, ktoré oznaèujú, èi i-ty prvok vektora je pouitı.
 \item \textbf{Nelineárne} - zvyèajne reprezentované grafovou štruktúrou, reprezentujú sa tam stavy jedno k jednej, jedno ku viacerım, viaceré ku jednej, medzi riešeniami a reprezentáciami riešení
\end{my_itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/Nonlinearkoding.png}
    \caption{Vizuálne zobrazenie nelinárnej reprezentácie riešení}
    \label{fig:NonLinearSol}
\end{figure}

Vo ve¾kom mnostve problémov môe by funkcia zadaného optimalizaèného problému aj jeho cie¾ovou funkciou. Typickım príkladom je optimalizácia spojitıch viac rozmernıch funkcií, kde sa optimum funkcie dá ¾ahko porovna ako èíslo. Avšak napríklad pri funkciách, ktorıch vısledkom je len pravdivostná hodnota, je aké odlíši lepšie a horšie riešenie. Pri takıchto prípadoch je moné napríklad hodnoti riešenie pod¾a toho ko¾ko èastí je nesprávnych etc.. Ïalším prípadom cie¾ovej funkcie, ktorú je potrebné upravova sú funkcie, ktoré je príliš nákladné poèíta. Takéto funkcie môu by nahradené funkciou, ktorá ráta odhad tejto funkcie a tak urıchli beh metaheuristiky\cite{MetaMainBook}.

Metaheuristiky a heuristiky môeme deli\cite{ReviewNatureInspired} pod¾a rôznych kritérií:
\begin{my_itemize}
 \item
 {
    \textbf{Prírodou inšpirované vs. Ostatné} - Prírodou inšpirované algoritmy môeme deli na
    \begin{my_itemize}
     \item Biologicky inšpirované \ref{fyz_chem_algo}
     \item Fyzikou a chémiou inšpirované \ref{bio_algo}
     \item Ostatné
    \end{my_itemize} 
 }
, avšak deli prírodou inšpirované metaheuristky je zloité, pretoe algoritmy môu naraz spada do viacerıch kategórií alebo aj do iadnej, resp. je zloité urèi pod¾a èoho a ako detailne by sa heuristiky mali deli.
 
 \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/Delenie.png}
    \caption{Diagram delenia prezentovaného v tejto práci}
    \label{fig:Delenie}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        Skratka & Názov\\
        \hline
        BBBC & Big Bang Big Crunch\cite{BBBC} \\
        
        GSA & H¾adanie gravitáciou (Gravitational search algorithm) \\
        
        SA & Simulované íhanie (Simulated annealing)\cite{SA} \\
        
        PSO & Optimalizácia rojom èastíc (Particle swarm optimization)\cite{kennedy2011particle}\\
        PS2O & PS2O\cite{chen2008optimization}\\
        MSA & Optimalizacia h¾adaní molí (Moth search optimization)\cite{wang2016moth}\\
        BA & Optimalizacia netopiermi(Bat algorithm) \cite{yang2010new} \\
        QIGA & Kvantovo-inšpirovanı genetickı algoritmus\cite{QIGA} \\
        DE & Diferenciálna evolúcia\cite{storn1997differential} \\
        GASA & Genetické simulované íhanue\cite{GASA} \\
        FPO & Optimalizácia ope¾ovaním kvetov\cite{yang2012flower}\\
        ASO & Optimalizácia anrachistickou spoloènosou \cite{ahmadi2011anarchic}\\
        \hline
    \end{tabular}
    \caption{Vysvetlenie skratiek v diagrame delenia}
    \label{tab:my_label}
\end{table}
 

 \item \textbf{S pouitím pamäte vs. Bez pouitia pamäte} - heuristiky bez pouitia pamäte sú napríklad tie, ktoré pouívajú princíp Markovovej reaze, tzn. e si nepamätajú navštívené stavy
 \item \textbf{Zaloené na populácií vs. Zaloené na jednom riešení} - heuristiky zaloené na jednom riešení pouívajú len jedno zvyèajne najlepšie riešení a na základe neho ho vylepšujú.
 
 \item \textbf{Deterministické vs. Stochastické}
\end{my_itemize}
\cite{MetahYang,MetaMainBook,MetahA}

\subsection{Prírodou inšpirované algoritmy}
\subsubsection{Fyzikou a chémiou inšpirované algoritmy}\label{fyz_chem_algo}
Fyzikou inšpirované algoritmy sú, ako je zrejmé z názvu, optimalizaèné algoritmy inšpirované fyzikálnymi procesmi a zákonmi vo vesmíre. Zaèiatok takıchto algoritmov mono h¾ada po publikovaní práce o kvantovo-inšpirovanıch poèítaèoch v roku 1982\cite{QMechComp}. Táto práca otvorila cestu prvému fyzikálne zaloenému algoritmu v roku 1995 nazvanému Kvantovo-inšpirovanı genetickı algoritmus\cite{QIGA}. Hlavnı "boom" takıchto algoritmov sa zaèal po roku 2000, keï sa zaèali vznika fyzikálne algoritmy inšpirované rôznymi oblasami fyzika ako je Newtonov gravitaènı zákon (Algoritmus gravitaènım h¾adaním - GSA, Optimalizácia centrálnou silou - CFO,...), teóriou vesmíru (Big Bang Big Crunch), elektromagnetizmom  alebo kvantovou mechanikou (Kvantovo inšpirovanı roj èastíc - QIPS)\cite{PhysicsSurvey}.
\subsubsection*{Kvantovo-inšpirovanı genetickı algoritmus}
Tento fyzikálne inšpirovanı algoritmus je prvı z fyzkálne inšpirovanıch algoritmov a vznikol v roku 1995. Tento algoritmus je zaloenı  na benom genetickom algoritme, kde populácia chromozómov riešení mutuje, kríi sa a na základe následne vypoèítanej fitnes funkcie novo vzniknutıch jedincov sa vyberie n jedincov do ïalšej generácie. V tomto algoritme sa však pri vıpoète neberie do úvahy len "dobros" riešenia, ale aj to ako ve¾mi sa líšia riešenia od najlepšieho riešenia (èím viac, tım lepšie). Takımto spôsobom sa udriavame lokálne optimá, ktoré potom pomáhajú pri h¾adaní globálnych optím.
Odlišnosou tohoto algoritmu od beného genetického algoritmu je pouitie princípu superpozície elektrónov. Superpozícia elektrónov znamená, e pod¾a toho akú energiu má elektrón, tak sa môe s nejakou pravdepodobnos nachádza na viacerıch vrstvách okolo jadra atómu. Toto je vyuité aj v tomto algoritme v zmysle, e existuje viacero vesmírov, kde sa rieši benı genetickı algoritmus a tieto sa môu navzájom kríi a mutova. Toto však môe nasta len medzi génmi v chromozóme na rovnakej pozícií i. Tımto sa simuluje preskakovanie elektrónu z vrstvy na vrstvu\cite{QIGA}.
\subsubsection*{Big Bang Big Crunch}
Big Bang Big Crunch je ïalším fyzikou inšpirovanım algoritmom. Hlavnım princípom, ktorım sa tento algoritmus inšpiruje je rozptılenie hmoty a energie vo vesmíre (Big bang) a následné zhlukovanie tejto hmoty vo vhodnıch pozíciách ako sa energia vesmíru zniuje (Big crunch). Tento algoritmus je zaloenı na populácií agentov, take sa dá klasifikova ako rojovı.
Algoritmus funguje tak, e najprv sa vytvorí poèiatoèná náhodná populácia v n-rozmernom priestore (Big bang). Potom sa pomocou rovnice \ref{BigCrunchEq} vypoèíta "stred hmoty", èie stred z vygenerovanıch bodov (Big crunch). 
\begin{equation}\label{BigCrunchEq}
   x^{\xrightarrow{}c} = \frac{\sum_{i=1}^{N}\frac{1}{f^i}x^{-i}}{\sum_{i=1}^{N}\frac{1}{f^i}}
\end{equation}
,  \(x^{i}\) je i-ty vygenerovanı bod a \(f^i\) je fitnes funkcia bodu \(x^i\).\newline
Následne zasa nasleduje fáza "Big bang", ktorá u ale negeneruje body náhodne, ale sú tieto body vygenerované rovnicou \ref{BigBangEq}, ktorá prièíta alebo odèíta èíslo na základe normálneho rozdelenia, ktorého variancia sa s pribúdajúcimi iteráciami zniuje.
\begin{equation}\label{BigBangEq}
x^{new} = x^{c} + lr/k
\end{equation}
,kde \(x^c\) je stred hmoty, l je hornı limit parametra, r je náhodné èíslo z normálneho rozdelenia a k je poèet iterácií.
Big crunch v tomto algoritme reprezentuje proces exploitácie a Big bang reprezentuje proces explorácie, ktorá sa ale s iteráciami zniuje, kvôli zniovaniu variancie a tım pádom nišej pravdepodobnosti vysokıch èísel. 
\subsubsection{Biologicky inšpirované algoritmy}\label{bio_algo}
 Biologicky inšpirované algoritmy sú druhom prírodou inšpirovanıch algoritmov, ktoré vznikli na základe pozorovania správania ivoèíchov alebo procesov ktorımi na nich vplıvala príroda. Takıto proces je napríklad evolúcia alebo symbióza. Algoritmy sa inšpirovali rôznymi druhmi zvierat, èi u malımi ako baktérie a salpy, alebo ve¾kımi ako veleryby alebo slony. Zvyèajne sa tieto algoritmy inšpirujú spôsobom h¾adania potravy alebo lovu tıchto zvierat. Príroda je dobrım zdrojom inšpirácie optimalizaènıch algoritmov, pretoe príroda mala milióny rokov na optimalizáciu správania zvierat a ivoèíchov. 
%\subsubsection*{Návrhové vzory pouité pri tvorbe biologicky inšpirovanıch algoritmov}
\subsubsection*{Evoluèné a genetické algoritmy}
Evoluèné a genetické algoritmy sú algoritmy zaloené na princípe evolúcie v prírode. Vo všeobecnosti sú to stochastické algoritmy zaloené na populácií, kde preíva nejsilnejší jedinec, tzn. jedinec s najlepšou hodnotou cie¾ovej funkcie. Vlastnos evolúcie je v tom, e populácie v ïalších iteráciách sú vytvorené z predchádzajúcich populácií mutaènımi a rozmnoovacími sa operátormi. Základy genetickıch algoritmov poloil John Holland v roku 1975\cite{JHollandGen}. Príkladom novšieho genetického algoritmu je Optimalizácia pomocou ryového po¾a\cite{PaddyField}. Genetické a evoluèné algoritmy rıchlo strácajú efektivitu pri multimodálnych a vysoko rozmernıch problémoch, kde je vysoká pravdepodobnos uviaznutia v lokálnom optime alebo potrebnı vysokı poèet iterácií\cite{BioInspiredOverview}.
\paragraph{Genetické simulované íhanie}
Genetické simulované íhanie je algoritmus, ktorı spája vlastnosti simulovaného íhania a genetického algoritmu. Algoritmus prebehne rovnako ako benı genetickı algoritmus, avšak na konci sa okrem najlepších, optimálnych riešení sa do populácie pridajú aj zlé riešenia na základe pravdepodobnosti p, ktorá sa s pribúdajúcimi iteráciami zmenšuje.\cite{GASA}

\subsubsection*{Rojovo inšpirované algoritmy}

Rojovo inšpirované optimalizaèné algoritmy sú všetky optimalizaèné algoritmy, ktoré pouívajú princíp rojovej inteligencie. Rojová inteligencia je princíp zaloenı na sociálnom správaní rojov, kàd¾ov a stád v prírode. Je to hlavne odpozorovanie princípu sociálneho h¾adania potravy takıchto rojov. Pri tomto princípe je vidie, e h¾adanie potravy jedincom bıva neúspešnejšie ako h¾adanie potravy rojom, pretoe jedinec nedokáe vníma celé prostredie ako celok a tım pádom, je moné, e sa jedinec na základe neúplnıch informácií rozhodne pre neoptimálne riešenie. Avšak ak je jedinec ovplyvòovanı ïalšími jedincami roja, tak tí ho vedia svojím vplyvom pritiahnu k optimálnemu riešeniu. Teda môeme rojom oznaèi roj, kedy samostatnı èlenovia roja sú sami osebe povaovanı za neinteligentné èasti, avšak v roji sa správajú ako ucelenı inteligentnı systém schopnı riešenia zloitıch problémov. Základnou charakteristikou rojovıch optimalizaènıch algoritmov je populácia agentov zbierajúcich informácie v priestore h¾adania. Tieto agenty potom na základe získanıch informácií o priestore h¾adania menia svoje správanie a pozíciu\cite{gazi2011swarm}. Takéto algoritmy väèšinou pri zbere informácií uplatòujú 4 základné princípy na spracovanie tıchto informácií a to \textbf{rozširovanie}, \textbf{spájanie}, \textbf{vyparovanie} a \textbf{odpudzovanie}.

\textbf{Rozširovanie} - spoèíva v tom, e jednotlivé agenty zdie¾ajú nájdené informácie o priestore s ostatnımi èasticami. Buï tieto informácie zdie¾ajú len so susednımi agentami, èo sa oznaèuje ako \textit{lbest} topológia alebo ich zdie¾ajú so všetkımi ostatnımi agentami, èo sa oznaèuje ako \textit{gbest} topológia\cite{kennedy2006swarm}.

\textbf{Spájanie} - vyjadruje, e získané informácie sú nejako spracované a spájané, pretoe uchováva všetky získané informácie je zbytoèné a systém zaaujúce. Napr. ráta sa z nich priemer.

\textbf{Vyparovanie} - vyparovaním sa oznaèuje zniujúca sa relevancia získanıch informácií s èasom. Ako analógia sa dá poui vyparovanie sa feromónov mravcov s èasom a tım pádom slabšia príalivos cesty, na ktorej sú tieto feromóny.

\textbf{Odpudzovanie} - je princíp, ktorı zaruèuje, e agenty sa nebudú naraz nachádza na jednom a tom istom mieste rovnako ako sa v "rojoch" zvierat nemôe na jednom a tom istom mieste nachádza viacero jednotlivcov\cite{fernandez2013description}.

Taktie, aby bol roj schopnı h¾adanie v priestore h¾adania musí spåòa tieto základné pravidlá:
\begin{my_itemize}
 \item populácia musí by schopná reagova na podmienky prostredia
 \item populácia musí by schopná robi jednoduchı priestorové a èasové vıpoèty
 \item populácia musí by nemala meni svoje správanie pri kadej zmene prostredia
 \item populácia by mala zmeni svoje správanie, ak je zmena prostredia nato¾ko ve¾ká, e to stojí za vıpoètovú cenu zmeny
\end{my_itemize}
\paragraph{Optimalizácia rojom èastíc (Particle Swarm Optimization)}
Optimalizácia rojom èastíc je jednım z prvıch rojovıch algoritmov navrhnutı v roku 1995. Tento algoritmus je stochastickı optimalizaènı algoritmus zaloenı na populácií. Optimalizácia rojom èastíc je algoritmus zaloenı na sociálno-psychologickej metafory riešenia problému èlovekom. Èlovek, ktorı má rieši problém ho väèšinou rieši komunikáciou s inımi ¾uïmi. Potom ovplyvnenı riešeniami okolo seba a svojím vlastnım presvedèením dôjde k nejakému záveru. V kontexte vektorov v n-dimenzionálnom priestore to môeme vyjadri pohybom bodu, ktorı je danı takouto rovnicou
\begin{equation}
    v_{id}^{t+1} = \alpha v_{id}^{t} + U(0,\beta)(p_{id} - x_{id}^{t}) + U(0,\beta)(p_{gd} - x_{id}^{t})
\end{equation}
\begin{equation}
    x_{id}^{t+1} = x_{id}^{t} + v_{id}^{t} 
\end{equation}
,kde \(v_{id}\) je rıchlos i-tej èastice v dimenzii d, \(p_{id}\) je najlepšie dosia¾ dosiahnuté riešenie èasticou i a \(p_{gd}\) je najlepšie dosia¾ dosiahnuté riešenie susedmi èastice i. 

Existuje aj varianta uvedená v roku 2004, kde sa namiesto najlepšieho riešenia zo susedov berie do úvahy priemer najlepších riešení susedov.\cite{mendes2004population}

Celkovo sa tento algoritmus dá v benej reèi charakterizova ako Nová pozícia = Stará pozícia + sociálny vplyv + vytrvalos.\cite{kennedy2011particle}.

\subsubsection*{Ostatné}
Keïe presná klasifikácia biologicky inšpirovanıch algoritmov neexistuje do tejto sekcie sme zaradil všetky, ktoré sme dosia¾ nezaradili, take napríklad bio-inšpirované algoritmy, ktoré nie sú rojovo inšpirované. Takéto algoritmy sa zasa môu ïalej deli pod¾a èasti prírody, ktorou boli inšpirované napríklad na algoritmy inšpirované ekológiou ako je napríklad obmenená Optimalizácia rojom èastíc \textbf{PS2O} \ref{ps20}, ktorá sa zamerala na vzahy v ekosystémoch. Ïalšími algoritmami sú algoritmy, ktoré sa nezamerali na konkrétnu oblas biológie, ale inšpirovali sa òou a nie sú rojovo inšpirované. Takım to príkladom je napríklad \textbf{Optimalizácia ope¾ovaním kvetov} \ref{opelKvety}\cite{binitha2012survey}.
\paragraph{PS2O} \label{ps20}
Tento algoritmus vzahy v ekosystémoch modeluje tak, e populácia èastíc je rozdelená na rôzne druhy. Jedinci jedného druhu medzi sebou spolupracujú ako v klasickom PSO, avšak druhy spolupracujú medzi sebou v symbióze, a to tak, e symbiotickému druhu poskytnú svoje najlepšie nájdené informácie a tak jedincov ovplyvòujú aj jedince iného druhu. Túto topológiu jedincov mono vidie na obrázku \ref{fig:PS2O} Ak však sa iadny jedinec z populácie po danom konštantnom poète iterácií algoritmu nezlepší, znamená to, e jedinci sú pod silnım stresom prostredia. Tım pádom náhodne vybraná polovica druhov vymrie a nahradia ich nové druhy. Takto sa modeluje zaseknutie optimalizácie v lokálnom minime a následne náhodná reinicializácia populácie\cite{chen2008optimization}. 
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/figure2.png}
    \caption{Topológia komunikácie druhov a jedincov s topológiou \textit{lbest}}
    \label{fig:PS2O}
\end{figure}
\paragraph{Optimalizácia ope¾ovaním kvetov}\label{opelKvety}
Ope¾ovanie je jedinım z najèastejších spôsobov rozmnoovania v rastlinnom svete. Tak ako pri väèšine spôsobov rozmnoovania sa najviac dokáe rozmnoova najlepší jedinec. Existujú dva rôzne druhy ope¾ovania a to biotické a abiotické. Biotické ope¾ovanie je ope¾ovanie hlavne hmyzom, a tım pádom, na dlhšie vzdialenosti. Abiotické ope¾ovanie je ope¾ovanie najèastejšie sebou samım alebo vetrom, èo je hlavne moné na kratšie vzdialenosti. Potom tieto dva princípy boli pretavené do algoritmu tak, e na aktualizáciu terajšej pozície, buï princíp zaloenı na biotickom ope¾ovaní alebo abiotickom.
Princíp zaloenı na biotickom ope¾ovaní berie do úvahy terajšiu pozíciu kvetu vzh¾adom na pozíciu najlepšieho kvetu v populácií, ktorıch vzah je parametrizovanı èíslom z Lévyho rozdelenia. Toto rozdelenie slúi na urèenie náhodnej dåky kroku. Abiotické ope¾ovanie reprezentuje aktualizácia na základe vzahu medzi kvetom a ïalším náhodnım kvetom v populácií, ktorı je parametrizovanı náhodnım èíslo z rovnomerného rozdelenia, èo z tohoto robí náhodné lokálne h¾adanie\cite{yang2012flower}.

\subsection{Ostatné}
Do tejto kategórie patria všetky ostatné algoritmy, ktoré je aké zaradi do niektorej z predchádzajúcich kategórií, pretoe boli inšpirované z viacerıch zdrojov ako napríklad sociológia alebo emócie.
\paragraph{Optimalizácia anarchistickou spoloènosou}
Optimalizácia anarchistickou spoloènosou je algoritmus zaloenı na ¾udskej spoloènosti, ktorej jedinci sa so zhoršujúcou situáciou správajú viac nepredvídate¾ne. Tento princíp sa uplatòuje pri vıber ïalšej pozície. V tomto algoritme existujú tri druhy vıberu ïalšej pozície a to 
\begin{my_itemize}
 \item \textbf{zaloenı na terajšej pozícií} - v tejto metóde sa uplatòujú metódy pohybu v lokálnom susedstve jedinca. Tieto metódy sa vyberajú pod¾a tzv. \textit{indexu nestálosti}, ktorı je ovplyvnenı tım, ako ve¾mi sa jedinec cíti nespokojnı so svojou situáciou oproti ostatnım jedincom v populácií.
 \item \textbf{zaloenı na pozíciach inıch jedincov} - táto metóda zakladá svoj pohyb na najlepšom jedincovi v populácií. Avšak jedinci sa v tomto algoritme môu správa aj nepredvídavo a svoj pohyb zaloi na pozícií ktoréhoko¾vek iného jedinca. To èi sa jedinci správajú nepredvídavo je zaloené na hodnote tzv. \textit{indexu vonkajšej iregularity}.
 \item \textbf{zaloenı na minulıch pozíciách} - pre tento tretí spôsob platia rovnaké princípy ako pre spôsob druhı, avšak aplikované na minulé pozície jedinca. Jedinec si taktie môe vybra aj iné ako optimálne pozície na základe hodnoty nazvanej \textit{index vnútornej iregularity}.
\end{my_itemize}
Vısledky všetkıch tıchto pohybov je potom nutné agregova v jeden vısledok. Pouité metódy by mali závisie od problému. Príkladom kombinaènej metódy je  pouitie najlepšieho vısledku alebo mutácia vıslednıch pozícií inšpirovaná genetickım algoritmom.
\cite{ahmadi2011anarchic}
\subsection{Uèenie zaloené na opaènej hodnote (Opposition based learning)}
%tu urcite fig ako funguje OBL
Uèenie zaloené na opaènıch hodnotách je metóda na zlepšenie rıchlosti konvergencie uèiacich sa a optimalizaènıch algoritmov predstavená v roku 2006.\cite{OBLorig}. Táto metóda je zaloená na princípe, e v najhoršom prípade pri náhodnom vybraní hodnôt na zaèiatku algoritmov je táto hodnota na 'opaènej strane' ako vidno na obrázku \ref{fig:OblNormal}. Takımto spôsobom sa môeme spoèiatku rapídne priblíi k optimálnej hodnote. Túto metódu môeme matematicky v n-rozmernom priestore vyjadri takto
\begin{equation}
    \Breve{x}_{i} = a_i + b_i - x_i 
\end{equation}
,kde \(\Breve{x}_{i}\) je i-tá hodnota vektora súradníc opaèného riešenia a \(a_i\) a \(b_i\) sú ohranièenia tejto dimenzie priestoru, v ktorom h¾adáme a \(x_i\) je i-tá súradnica riešenia, ku ktorému h¾adáme opaèné riešenie.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/OblNormal.png}
    \caption{Príklad pouitia opozície typu-I na zrıchlenie konvergencie}
    \label{fig:OblNormal}
\end{figure}

Takáto metóda je nazıvaná opozícia typu-I a po jej publikácií bola implementovaná v mnostve rôznych optimalizaènıch heuristík ako napr. Optimalizácia pomocou mravcolevov\cite{AntLionOBL} alebo Vylepšená optimalizácia pomocou cvrèkov\cite{GrasshopperOBL}. Taktie vznikli upravené metódy uèenia zaloené na opaènej hodnote. Sú nimi napríklad úpravy opozície typu-I, ktoré umoòujú opaènému bodu by pred ním resp. za ním s názvami \textbf{Kvázi opozícia typu-I} resp. \textbf{Super opozícia typu-I}\cite{OBLsurvey}. Tie vznikli metódy zaloené na u nájdenom optime a h¾adania opaènej hodnoty vzh¾adom na neho, nie vzh¾adom na priestor h¾adania. Takáto metóda môe by v n-rozmernom priestore reprezentovaná rovnicou
\begin{equation}
    \Breve{x} = 2x_{co} - x
\end{equation}
,kde \(x_{co}\) je doterajšie optimum a x je riešenie, ku ktorému h¾adáme opaènı riešenie. Takımto spôsobom však môeme vytvori riešenie, ktorı sa nachádza mimo priestoru h¾adania. Takéto riešenie nahradíme náhodne vygenerovanım riešením\cite{COOBL}.Na obrázku \ref{fig:COOBL} je vidno úspešne zlepšenie vısledku pomocou tohoto princípu.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/COOBL.png}
    \caption{Príklad pouitia opozície na doteraz nájdenom optime. Doteraz nájdené optimum je oznaèené ako co, globálne optimum ako go}
    \label{fig:COOBL}
\end{figure}

%bezne OBL na tie mole, co prehladavaju Optimum obl na tie co exploituju

\subsection{Biologicky inšpirované algoritmy v CRAN-e}

Jazyk R je jazyk orientovanı na štatistické operácie a spracovanie dát. Preto je zrejmé, e mnostvo modulov tohoto jazyka bude orientované na h¾adanie optima vo funkciách. A keïe našou úlohou je implementova balíèek jazyka R s optimalizaènım algoritmom. Je potrebné, aby sme sa oboznámili u s existujúcimi balíkmi spåòajúce rovnakı princíp. CRAN obsahuje viacero evoluènıch algoritmov ako Diferenciálna evolúcia alebo genetickı algoritmus. Z rojovıch algoritmov podobnıch nášmu implementovanému algoritmu sú to algoritmy ako Optimalizácia rojom èastíc, Optimalizácia netopiermi, Optimalizácia umelou kolóniou vèiel, Optimalizácia svätojánskymi muškami. Tieto informácie boli zozbierané, aby sme sa vyhli implementácií u existujúceho balíèka. Podrobnejší zoznam optimalizaènıch funkcií v \hyperlink{https://cran.r-project.org/web/views/Optimization.html}{CRAN-e}.

\section{Zhodnotenie}

S postupom technológie je èoraz èastejšie potrebné optimalizova také NP-problémy. Existuje ve¾ké mnostvo postupov ako optimalizova takéto problém. Sú to napríklad exaktné metódy na zistenie optima problémov ako dynamické programovanie a lineárne programovanie alebo iteratívne metódy, ktoré pomocou matematickıch vzahov zisujú smer postupu. Avšak takéto metódy pri ve¾kosti a mnohıch dimenziách dnešnıch problémov nedokáu poskytova riešenia v prijate¾nom èase. Tu prichádzajú do úvahy stochastické metaheuristky na riešenie takıchto NP-komplexnıch problémov, ktoré ponúkajú rozumnı kompromis medzi úplnou presnosou vısledku a èasom, ktorı je potrebnı na získanie takého to vısledku.
Tieto metaheuristky sú vo väèšine prípadov inšpirované prírodou a jej spôsobom získavania optimálnych stratégií.

Z preskúmanıch metaheuristík zisujeme, e tieto metaheuristky vo väèšine prípadov pozostávajú z dvoch princípov a to preh¾adávanie priestoru h¾adania a vyuívania doteraz nájdeného najlepšieho riešenia. Na preh¾adávanie priestoru riešenia sú pouívané rôzne spôsoby náhodnıch pohybov v priestore riešenia ako Lévyho lety, náhodnı pohyb alebo aj uèenia na základe opaènej hodnoty, ktorá preh¾adáva opaènú stranu okolo optima resp. opaènú stranu priestoru h¾adania. Vyuívanie doteraz nájdeného najlepšieho riešenia sa prejavuje v pouívaní jeho pozície ako referenèného bodu pre h¾adanie ïalších pozícií. V tejto analıze sme zistili, e pre nájdenie vısledku správne a rıchlo je dôleité tieto dve fázy riešenia správne rovnomerne pouíva a s beiacim èasom riešenia upravova ich pomer.